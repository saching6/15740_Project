{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code implements the training pipeline for various models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from dataformatter import *\n",
    "from models import *\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pdb\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "\t# Esp important for ensuring deterministic behavior with CNNs\n",
    "\ttorch.backends.cudnn.deterministic = True\n",
    "\tnp.random.seed(seed)\n",
    "\trandom.seed(seed)\n",
    "\ttorch.manual_seed(seed)\n",
    "\tcuda_available = torch.cuda.is_available()\n",
    "\tif cuda_available:\n",
    "\t\ttorch.cuda.manual_seed_all(seed)\n",
    "\treturn cuda_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(model, optimizer, data_iterator, mode='train', eval_frac=-1):\n",
    "    model.train()\n",
    "    if mode == 'val':\n",
    "        model.eval()\n",
    "    stats = []\n",
    "    max_tr_batch = -1\n",
    "    num_egs, batch_idx, n_ones = 0, 1, 0\n",
    "    for batch in data_iterator:\n",
    "        # we get the loss from passing the batch to the model\n",
    "        # each model will have it's own way of deadling with the data [we can jointly figure this out]\n",
    "        if eval_frac > 0:\n",
    "            batch, num_batches = batch\n",
    "            max_tr_batch = int(eval_frac * num_batches)\n",
    "            n_ones = (np.array(batch)[:, -1]).sum()\n",
    "        loss, acc, bsz = model(batch)\n",
    "        stats.append([loss.item(), acc.item(), bsz, n_ones, len(batch)])\n",
    "        if mode == 'train' and ((batch_idx < max_tr_batch) or (max_tr_batch < 0)):\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n",
    "            optimizer.step()\n",
    "        batch_idx += 1\n",
    "    stats = np.array(stats)\n",
    "    avg_loss = np.mean(stats[:, 0])\n",
    "    avg_acc = (stats[:, 1]).sum() / (stats[:, 2].sum() * 1.0)\n",
    "    return (avg_loss, avg_acc), stats[max_tr_batch:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model, optimizer, dataset, num_epochs=20, desc='Description of model', eval_frac=0.8, shuffle=True):\n",
    "    # Todo [all]\n",
    "    # Figure out how to split the data into a train-val-test regime\n",
    "    stats = []\n",
    "    for epoch_ in range(num_epochs):\n",
    "        # get a data iterator for this epoch\n",
    "        data_iter = get_batch_iterator(dataset, BATCH_SZ, shuffle=shuffle, batch_info=True)\n",
    "        epoch_stats, e_stats = run_epoch(model, optimizer, data_iter, mode='train', eval_frac=eval_frac)\n",
    "        stats.append(epoch_stats)\n",
    "        print('Epoch {} : Avrg Loss = {}, Avrg Acc = {} '.format(epoch_, stats[-1][0], stats[-1][1]))\n",
    "        major_acc = (e_stats[:, 3].sum()) / (1.0 * e_stats[:, 4].sum())\n",
    "        major_acc = max(major_acc, 1.0 - major_acc)\n",
    "        print('Epoch {} : Eval Loss = {}, Eval Acc = {}, Eval Majority Acc = {}'.format(epoch_, (e_stats[:, 0]).mean(), (e_stats[:, 1].sum())/(1.0 * e_stats[:, 2].sum()), major_acc))\n",
    "        print('-'*50)\n",
    "\n",
    "    stats = np.array(stats)\n",
    "#     graph_results(stats, desc)\n",
    "    return model\n",
    "\n",
    "def set_wise_trainer(model, optimizer, setwise_dataset, num_epochs=20, desc='Set-Wise Model', shuffle=False):\n",
    "    model.train()\n",
    "    stats = defaultdict(list)\n",
    "    for epoch_ in range(num_epochs):\n",
    "        # get a data iterator for this epoch\n",
    "        accs = []\n",
    "        setwise_keys = list(setwise_dataset.keys())\n",
    "        perm = np.random.permutation(len(setwise_keys))\n",
    "        setwise_keys = np.array(setwise_keys)[perm]\n",
    "        for set_id  in setwise_keys:\n",
    "            dataset = setwise_dataset[set_id]\n",
    "            model.remap_embedders(dataset, set_id)\n",
    "            data_iter = get_batch_iterator(dataset, BATCH_SZ, shuffle=shuffle)\n",
    "            this_stats, _ = run_epoch(model, optimizer, data_iter, mode='train')\n",
    "            stats[set_id].append(this_stats)\n",
    "            accs.append(this_stats[-1])\n",
    "        acc_stats = np.min(accs), np.mean(accs), np.median(accs), np.max(accs)\n",
    "        print('Min Acc {} | Mean Acc : {} | Median Acc {} | Max Acc {} '.format(*acc_stats))\n",
    "    return model, stats\n",
    "\n",
    "def evaluate(model, dataset, epoch_=-1, print_res=True, shuffle=False):\n",
    "    # get a data iterator for this epoch\n",
    "    model.eval()\n",
    "    data_iter = get_batch_iterator(dataset, BATCH_SZ, shuffle=shuffle, batch_info=False)\n",
    "    epoch_stats, _ = run_epoch(model, None, data_iter, mode='test')\n",
    "    if print_res:\n",
    "        print('Epoch {} : Avg Loss = {} Avg Acc = {}'.format(epoch_, epoch_stats[0], epoch_stats[1]))\n",
    "    return epoch_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_setwise(eval_setwise_dataset, model, MAX_TR_KEY=0, desc='graph', epoch=-1):\n",
    "    all_stats = []\n",
    "    for id_, (set_id, this_dataset) in enumerate(eval_setwise_dataset.items()):\n",
    "        set_id = MAX_TR_KEY + int(set_id)\n",
    "        model.remap_embedders(this_dataset, set_id)\n",
    "        result = evaluate(model, this_dataset, print_res=False)\n",
    "        average_pred = np.mean(this_dataset[:, -1])\n",
    "        all_stats.append([*result, 1.0 - average_pred, average_pred])\n",
    "    av_res = np.mean(all_stats, axis=0)\n",
    "    print('[{}] Epoch[{}] : Loss {}, Acc {}, Major [0] Acc {}, Marjor [1] Acc {}'.format(desc, epoch, *av_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'hawkeye_trace_belady_graph.csv' # This is the CSV FILE WE ARE TRYING TO ANALYZE\n",
    "TR_DESC = 'GRAPH'\n",
    "EVAL_DATA_PATH = 'hawkeye_trace_belady_bzip.csv' # This is the CSV FILE WE ARE TRYING TO ANALYZE\n",
    "EVAL_DESC = 'BZIP'\n",
    "SAVE_FLDR = 'results'\n",
    "N_EPOCHS = 5\n",
    "MAX_GRAD_NORM = 0.1\n",
    "SET_WISE = True\n",
    "RANDOM_SEED = 140982301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_main():\n",
    "    if not os.path.exists(SAVE_FLDR):\n",
    "        os.makedirs(SAVE_FLDR)\n",
    "\n",
    "    set_random_seed(RANDOM_SEED)\n",
    "    print('Creating Model of type : {}, Batchsz = {}, Learning Rate = {}'.format(MODEL_TYPE, BATCH_SZ, LR))\n",
    "    model = get_model(MODEL_TYPE)\n",
    "    chosen_columns = model.get_data_columns()\n",
    "    train_dataset = csv_to_data(DATA_PATH, chosen_columns)\n",
    "    average_pred = np.mean(train_dataset[:, -1])\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    model.use_cuda = torch.cuda.is_available()\n",
    "    eval_dataset = csv_to_data(EVAL_DATA_PATH, chosen_columns)\n",
    "    print(model.feat_idx_map, torch.cuda.is_available())\n",
    "    print('This is the average accuracy : ', 1.0 - average_pred, ' From predicting all zeros')\n",
    "    \n",
    "    if not SET_WISE:\n",
    "        optimizer = Adam(model.parameters(), lr=LR)\n",
    "        model.prep_for_data(train_dataset, temp_order=True)\n",
    "        model = trainer(model, optimizer, train_dataset, num_epochs=N_EPOCHS, desc=MODEL_DESC, shuffle=False)\n",
    "    else:\n",
    "        train_setwise_dataset = group_by_set(train_dataset)\n",
    "        eval_setwise_dataset = group_by_set(eval_dataset)\n",
    "        all_tr_keys = list(train_setwise_dataset.keys())\n",
    "        val_keys = np.random.choice(all_tr_keys, size=int(0.2 * len(all_tr_keys)))\n",
    "        tr_keys = set(all_tr_keys) - set(val_keys)\n",
    "\n",
    "        vals = [len(x) for x in list(train_setwise_dataset.values())]\n",
    "        max_key = all_tr_keys[np.argmax(vals)]\n",
    "        # Logging-pre-training performance\n",
    "        model.prep_for_data(train_setwise_dataset[max_key], temp_order=True)\n",
    "        for set_id, this_dataset in train_setwise_dataset.items():\n",
    "            model.remap_embedders(this_dataset, set_id)\n",
    "\n",
    "        tr_val_setwise_dataset = {k: train_setwise_dataset[k] for k in val_keys}\n",
    "        train_setwise_dataset = {k: train_setwise_dataset[k] for k in tr_keys}\n",
    "\n",
    "        print('Logging Pre-Training Performance')\n",
    "        MAX_TR_KEY = max([int(x) for x in train_setwise_dataset.keys()]) + 1\n",
    "        eval_setwise(eval_setwise_dataset, model, MAX_TR_KEY=MAX_TR_KEY, desc=EVAL_DESC)\n",
    "        eval_setwise(tr_val_setwise_dataset, model, desc=TR_DESC)\n",
    "        optimizer = Adam(model.parameters(), lr=LR) # Now we can add all the model parameters to the optimizer\n",
    "        for i in range(N_EPOCHS):\n",
    "            model, stats = set_wise_trainer(model, optimizer, train_setwise_dataset, num_epochs=1)\n",
    "            eval_setwise(eval_setwise_dataset, model, MAX_TR_KEY=MAX_TR_KEY, desc=EVAL_DESC, epoch=i)\n",
    "            eval_setwise(tr_val_setwise_dataset, model, desc=TR_DESC, epoch=i)\n",
    "    torch.save(model.state_dict(), '{}/{}_saved_model.pth'.format(SAVE_FLDR, MODEL_DESC))\n",
    "    # Neeed to return the eval performance here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model of type : TRANSFORMER, Batchsz = 32, Learning Rate = 0.0001\n",
      "{'Program Counter': 0, 'Set Occupancy': 1, 'Belady Friendly': 2} True\n",
      "This is the average accuracy :  0.6618220085895503  From predicting all zeros\n",
      "Logging Pre-Training Performance\n",
      "[BZIP] Epoch[-1] : Loss 0.704139049822125, Acc 0.5210902236125422, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[-1] : Loss 0.7683464638166018, Acc 0.3600384794776119, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.9272463768115942 | Mean Acc : 0.9586082872660178 | Median Acc 0.9562878787878788 | Max Acc 0.99640625 \n",
      "[BZIP] Epoch[0] : Loss 2.4962187632012407, Acc 0.3850104996146359, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[0] : Loss 0.13434152012067993, Acc 0.9710202891791044, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.9272463768115942 | Mean Acc : 0.9599671433353215 | Median Acc 0.9582858435097241 | Max Acc 0.99640625 \n",
      "[BZIP] Epoch[1] : Loss 3.0870043789785155, Acc 0.39929967871911354, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[1] : Loss 0.1541360191655095, Acc 0.9710202891791044, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.9272463768115942 | Mean Acc : 0.9601638726929205 | Median Acc 0.9582858435097241 | Max Acc 0.99640625 \n",
      "[BZIP] Epoch[2] : Loss 1.6474364604435727, Acc 0.39929967871911354, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[2] : Loss 0.14721807561912087, Acc 0.9710202891791044, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.9272463768115942 | Mean Acc : 0.9616752991963329 | Median Acc 0.9637121212121212 | Max Acc 0.99640625 \n",
      "[BZIP] Epoch[3] : Loss 3.2825765964116247, Acc 0.39929967871911354, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[3] : Loss 0.1619780797316083, Acc 0.9710202891791044, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.9272463768115942 | Mean Acc : 0.9617691760851804 | Median Acc 0.9637121212121212 | Max Acc 0.99640625 \n",
      "[BZIP] Epoch[4] : Loss 3.845304863855681, Acc 0.39929967871911354, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[4] : Loss 0.18658197133320198, Acc 0.9710202891791044, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Creating Model of type : TRANSFORMER_1, Batchsz = 32, Learning Rate = 0.0001\n",
      "{'Program Counter': 0, 'Set Occupancy': 1, 'Belady Friendly': 2} True\n",
      "This is the average accuracy :  0.6618220085895503  From predicting all zeros\n",
      "Logging Pre-Training Performance\n",
      "[BZIP] Epoch[-1] : Loss 0.6550137290099661, Acc 0.6267591831649894, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[-1] : Loss 0.870803554104502, Acc 0.2544746968283582, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.8597355769230769 | Mean Acc : 0.9512915217884103 | Median Acc 0.9564985795454546 | Max Acc 0.9952392578125 \n",
      "[BZIP] Epoch[0] : Loss 2.6113131962337732, Acc 0.38085714320042735, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[0] : Loss 0.13923775922587844, Acc 0.9705355060634329, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.9253077651515151 | Mean Acc : 0.9600872839263103 | Median Acc 0.9608836145974673 | Max Acc 0.9952392578125 \n",
      "[BZIP] Epoch[1] : Loss 3.0694187880899872, Acc 0.3984950279952035, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[1] : Loss 0.15610007904588338, Acc 0.9705355060634329, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.9302536231884058 | Mean Acc : 0.9632315982849589 | Median Acc 0.9646661931818181 | Max Acc 0.9952392578125 \n",
      "[BZIP] Epoch[2] : Loss 2.4518589710596266, Acc 0.3984950279952035, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[2] : Loss 0.13495985152214635, Acc 0.9705355060634329, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.9302536231884058 | Mean Acc : 0.9626426517466632 | Median Acc 0.9646661931818181 | Max Acc 0.9952392578125 \n",
      "[BZIP] Epoch[3] : Loss 3.087679628709215, Acc 0.3984950279952035, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[3] : Loss 0.1559054633400945, Acc 0.9705355060634329, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.9291213768115942 | Mean Acc : 0.9630519791060087 | Median Acc 0.9646661931818181 | Max Acc 0.9952392578125 \n",
      "[BZIP] Epoch[4] : Loss 3.499925433895497, Acc 0.3984950279952035, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[4] : Loss 0.17338667882999723, Acc 0.9705355060634329, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Creating Model of type : TRANSFORMER_2, Batchsz = 32, Learning Rate = 0.0001\n",
      "{'Program Counter': 0, 'Set Occupancy': 1, 'Belady Friendly': 2} True\n",
      "This is the average accuracy :  0.6618220085895503  From predicting all zeros\n",
      "Logging Pre-Training Performance\n",
      "[BZIP] Epoch[-1] : Loss 0.6653352619793378, Acc 0.6349599473256359, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[-1] : Loss 1.0327058193802054, Acc 0.062019917502332086, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.9302536231884058 | Mean Acc : 0.9587774735394495 | Median Acc 0.9564985795454546 | Max Acc 0.9952392578125 \n",
      "[BZIP] Epoch[0] : Loss 2.876622733661937, Acc 0.3420147341519199, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[0] : Loss 0.14136562608538628, Acc 0.9705355060634329, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.8504971590909091 | Mean Acc : 0.9545398648598693 | Median Acc 0.9608836145974673 | Max Acc 0.9952392578125 \n",
      "[BZIP] Epoch[1] : Loss 3.4296203612160903, Acc 0.3840637663347557, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[1] : Loss 0.16821122547727685, Acc 0.9705355060634329, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.8284855769230769 | Mean Acc : 0.9526307673903099 | Median Acc 0.9608836145974673 | Max Acc 0.9952392578125 \n",
      "[BZIP] Epoch[2] : Loss 1.3492474212645975, Acc 0.39668620103624824, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[2] : Loss 0.19000445035592056, Acc 0.9705355060634329, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.6869169776119403 | Mean Acc : 0.9442348929046397 | Median Acc 0.9646661931818181 | Max Acc 0.9952392578125 \n",
      "[BZIP] Epoch[3] : Loss 3.7960425141777483, Acc 0.3445363059802781, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[3] : Loss 0.17592306756496465, Acc 0.9705355060634329, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.7490384615384615 | Mean Acc : 0.9462803956153456 | Median Acc 0.9608836145974673 | Max Acc 0.9952392578125 \n",
      "[BZIP] Epoch[4] : Loss 4.205425150982568, Acc 0.3969937453459498, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[4] : Loss 0.2064749351375959, Acc 0.9705355060634329, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Creating Model of type : TRANSFORMER, Batchsz = 32, Learning Rate = 0.0003\n",
      "{'Program Counter': 0, 'Set Occupancy': 1, 'Belady Friendly': 2} True\n",
      "This is the average accuracy :  0.6618220085895503  From predicting all zeros\n",
      "Logging Pre-Training Performance\n",
      "[BZIP] Epoch[-1] : Loss 0.704139049822125, Acc 0.5210902236125422, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[-1] : Loss 0.7683464638166018, Acc 0.3600384794776119, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.8713846153846154 | Mean Acc : 0.9532312023133326 | Median Acc 0.9562878787878788 | Max Acc 0.99640625 \n",
      "[BZIP] Epoch[0] : Loss 2.6769621662673124, Acc 0.3428817682713523, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[0] : Loss 0.13460300311662515, Acc 0.9710202891791044, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.6453030303030303 | Mean Acc : 0.9384191196199065 | Median Acc 0.9582858435097241 | Max Acc 0.99640625 \n",
      "[BZIP] Epoch[1] : Loss 3.2908874031417046, Acc 0.34581646976388963, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[1] : Loss 0.15259311714033907, Acc 0.9710202891791044, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.7866153846153846 | Mean Acc : 0.9484194738082231 | Median Acc 0.9581365897783809 | Max Acc 0.99640625 \n",
      "[BZIP] Epoch[2] : Loss 1.3763155099931317, Acc 0.39594140352702656, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[2] : Loss 0.18187834590207785, Acc 0.9710202891791044, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.9272463768115942 | Mean Acc : 0.9611996407859567 | Median Acc 0.9634848484848485 | Max Acc 0.99640625 \n",
      "[BZIP] Epoch[3] : Loss 3.4962801788774405, Acc 0.39448204495062167, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[3] : Loss 0.17182568543705826, Acc 0.9707964085820895, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.9271014492753623 | Mean Acc : 0.9618060290872509 | Median Acc 0.9637121212121212 | Max Acc 0.99640625 \n",
      "[BZIP] Epoch[4] : Loss 4.243051843719613, Acc 0.3992999227485272, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[4] : Loss 0.2052088959859967, Acc 0.9710202891791044, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Creating Model of type : TRANSFORMER_1, Batchsz = 32, Learning Rate = 0.0003\n",
      "{'Program Counter': 0, 'Set Occupancy': 1, 'Belady Friendly': 2} True\n",
      "This is the average accuracy :  0.6618220085895503  From predicting all zeros\n",
      "Logging Pre-Training Performance\n",
      "[BZIP] Epoch[-1] : Loss 0.6550137290099661, Acc 0.6267591831649894, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[-1] : Loss 0.870803554104502, Acc 0.2544746968283582, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.8237980769230769 | Mean Acc : 0.9502873290969759 | Median Acc 0.9564985795454546 | Max Acc 0.9952392578125 \n",
      "[BZIP] Epoch[0] : Loss 2.707678056984367, Acc 0.3420147341519199, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[0] : Loss 0.1372273129318952, Acc 0.9705355060634329, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.9232954545454546 | Mean Acc : 0.9598712454358151 | Median Acc 0.9608836145974673 | Max Acc 0.9952392578125 \n",
      "[BZIP] Epoch[1] : Loss 3.096053199559848, Acc 0.38412644124147216, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[1] : Loss 0.154419984757488, Acc 0.9705355060634329, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.6685096153846154 | Mean Acc : 0.941275001892221 | Median Acc 0.9608836145974673 | Max Acc 0.9952392578125 \n",
      "[BZIP] Epoch[2] : Loss 1.9804366382464087, Acc 0.3426691767825169, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[2] : Loss 0.13964749386216124, Acc 0.9705355060634329, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.8928404850746269 | Mean Acc : 0.9591698406426578 | Median Acc 0.9646661931818181 | Max Acc 0.9952392578125 \n",
      "[BZIP] Epoch[3] : Loss 3.1954446926468543, Acc 0.3971016044877408, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[3] : Loss 0.16066924984266706, Acc 0.9705355060634329, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.6742788461538461 | Mean Acc : 0.9408421602773143 | Median Acc 0.9608836145974673 | Max Acc 0.9952392578125 \n",
      "[BZIP] Epoch[4] : Loss 3.8193406311087217, Acc 0.3899668680138602, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[4] : Loss 0.18733673496691738, Acc 0.9705355060634329, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Creating Model of type : TRANSFORMER_2, Batchsz = 32, Learning Rate = 0.0003\n",
      "{'Program Counter': 0, 'Set Occupancy': 1, 'Belady Friendly': 2} True\n",
      "This is the average accuracy :  0.6618220085895503  From predicting all zeros\n",
      "Logging Pre-Training Performance\n",
      "[BZIP] Epoch[-1] : Loss 0.6653352619793378, Acc 0.6349599473256359, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[-1] : Loss 1.0327058193802054, Acc 0.062019917502332086, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.33052884615384615 | Mean Acc : 0.915245043956743 | Median Acc 0.9564985795454546 | Max Acc 0.9952392578125 \n",
      "[BZIP] Epoch[0] : Loss 3.217708637722845, Acc 0.3420197679792395, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[0] : Loss 0.15133518152575942, Acc 0.9705355060634329, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.13210227272727273 | Mean Acc : 0.9032812627283052 | Median Acc 0.9608836145974673 | Max Acc 0.9952392578125 \n",
      "[BZIP] Epoch[1] : Loss 3.5925336300074378, Acc 0.3420147341519199, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[1] : Loss 0.1650953841683565, Acc 0.9705355060634329, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.09314903846153846 | Mean Acc : 0.9001392405747343 | Median Acc 0.9608836145974673 | Max Acc 0.9952392578125 \n",
      "[BZIP] Epoch[2] : Loss 1.4038511510272913, Acc 0.3420147341519199, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[2] : Loss 0.19387415895384472, Acc 0.9705355060634329, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.07357742537313433 | Mean Acc : 0.9004844045836108 | Median Acc 0.9646070075757576 | Max Acc 0.9952392578125 \n",
      "[BZIP] Epoch[3] : Loss 4.076880717552759, Acc 0.3420147341519199, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[3] : Loss 0.18448531522194367, Acc 0.9705355060634329, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.0140625 | Mean Acc : 0.8902337407303756 | Median Acc 0.9558528380823157 | Max Acc 0.9952392578125 \n",
      "[BZIP] Epoch[4] : Loss 5.238895604091726, Acc 0.3420147341519199, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[4] : Loss 0.2347922988889212, Acc 0.9705355060634329, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Creating Model of type : TRANSFORMER, Batchsz = 64, Learning Rate = 0.0001\n",
      "{'Program Counter': 0, 'Set Occupancy': 1, 'Belady Friendly': 2} True\n",
      "This is the average accuracy :  0.6618220085895503  From predicting all zeros\n",
      "Logging Pre-Training Performance\n",
      "[BZIP] Epoch[-1] : Loss 0.7044548517141824, Acc 0.5201888261931629, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[-1] : Loss 0.765300269718423, Acc 0.3654450757575758, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.832125 | Mean Acc : 0.9492592439742695 | Median Acc 0.956060606060606 | Max Acc 0.997375 \n",
      "[BZIP] Epoch[0] : Loss 2.0384250095790835, Acc 0.3966041722288966, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[0] : Loss 0.11990037032537106, Acc 0.9745871212121212, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.8316363636363636 | Mean Acc : 0.9517800377819113 | Median Acc 0.956060606060606 | Max Acc 0.997375 \n",
      "[BZIP] Epoch[1] : Loss 2.1906798775686496, Acc 0.40064309438458523, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[1] : Loss 0.11838960417398167, Acc 0.9745871212121212, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.9281176470588235 | Mean Acc : 0.9614409299332382 | Median Acc 0.9603636363636363 | Max Acc 0.997375 \n",
      "[BZIP] Epoch[2] : Loss 1.7690950689398934, Acc 0.40064309438458523, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[2] : Loss 0.1290804095562745, Acc 0.9745871212121212, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.9281176470588235 | Mean Acc : 0.9614126069518717 | Median Acc 0.9603636363636363 | Max Acc 0.997375 \n",
      "[BZIP] Epoch[3] : Loss 2.3860411632539402, Acc 0.40064309438458523, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[3] : Loss 0.11932944791183356, Acc 0.9745871212121212, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.9281176470588235 | Mean Acc : 0.9614409299332379 | Median Acc 0.9603636363636363 | Max Acc 0.997375 \n",
      "[BZIP] Epoch[4] : Loss 3.2277241868469075, Acc 0.40064309438458523, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[4] : Loss 0.1404057135737138, Acc 0.9745871212121212, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Creating Model of type : TRANSFORMER_1, Batchsz = 64, Learning Rate = 0.0001\n",
      "{'Program Counter': 0, 'Set Occupancy': 1, 'Belady Friendly': 2} True\n",
      "This is the average accuracy :  0.6618220085895503  From predicting all zeros\n",
      "Logging Pre-Training Performance\n",
      "[BZIP] Epoch[-1] : Loss 0.6567701591492476, Acc 0.6253999176461882, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[-1] : Loss 0.8699664118502176, Acc 0.25538712318497475, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.7125651041666666 | Mean Acc : 0.9363018004339211 | Median Acc 0.956478851010101 | Max Acc 0.996826171875 \n",
      "[BZIP] Epoch[0] : Loss 1.9635274930417042, Acc 0.39782280068948866, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[0] : Loss 0.12107229243547683, Acc 0.9747277462121212, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.9284620098039216 | Mean Acc : 0.9612444531965042 | Median Acc 0.9594381313131313 | Max Acc 0.996826171875 \n",
      "[BZIP] Epoch[1] : Loss 2.2338407367156505, Acc 0.40007805580425915, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[1] : Loss 0.1172059518831895, Acc 0.9747277462121212, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.9284620098039216 | Mean Acc : 0.960044918422326 | Median Acc 0.956478851010101 | Max Acc 0.996826171875 \n",
      "[BZIP] Epoch[2] : Loss 1.8924368984843851, Acc 0.40007805580425915, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[2] : Loss 0.1202946028453439, Acc 0.9747277462121212, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.9284620098039216 | Mean Acc : 0.9614043404154522 | Median Acc 0.9601878156565656 | Max Acc 0.996826171875 \n",
      "[BZIP] Epoch[3] : Loss 2.2593325510137765, Acc 0.40007805580425915, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[3] : Loss 0.11753526548713897, Acc 0.9747277462121212, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.9284620098039216 | Mean Acc : 0.9614824307986123 | Median Acc 0.9601878156565656 | Max Acc 0.996826171875 \n",
      "[BZIP] Epoch[4] : Loss 2.840217383609005, Acc 0.40007805580425915, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[4] : Loss 0.12902262032884843, Acc 0.9747277462121212, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Creating Model of type : TRANSFORMER_2, Batchsz = 64, Learning Rate = 0.0001\n",
      "{'Program Counter': 0, 'Set Occupancy': 1, 'Belady Friendly': 2} True\n",
      "This is the average accuracy :  0.6618220085895503  From predicting all zeros\n",
      "Logging Pre-Training Performance\n",
      "[BZIP] Epoch[-1] : Loss 0.6653988576344921, Acc 0.6336623744416605, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[-1] : Loss 1.0362951351668346, Acc 0.06002283577967172, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.81201171875 | Mean Acc : 0.9467845521798351 | Median Acc 0.956478851010101 | Max Acc 0.996826171875 \n",
      "[BZIP] Epoch[0] : Loss 2.23153909286443, Acc 0.34376100241104557, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[0] : Loss 0.11922419511459091, Acc 0.9747277462121212, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.7693339646464646 | Mean Acc : 0.9474493741059088 | Median Acc 0.956478851010101 | Max Acc 0.996826171875 \n",
      "[BZIP] Epoch[1] : Loss 2.108616648828317, Acc 0.40007805580425915, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[1] : Loss 0.11860694981331824, Acc 0.9747277462121212, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.9284620098039216 | Mean Acc : 0.9613860035996035 | Median Acc 0.9601878156565656 | Max Acc 0.996826171875 \n",
      "[BZIP] Epoch[2] : Loss 1.4585845818733048, Acc 0.40007805580425915, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[2] : Loss 0.1584766505067378, Acc 0.9747277462121212, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.9284620098039216 | Mean Acc : 0.9613637311860267 | Median Acc 0.9601878156565656 | Max Acc 0.996826171875 \n",
      "[BZIP] Epoch[3] : Loss 2.4287099217626436, Acc 0.40007805580425915, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[3] : Loss 0.11934151333866105, Acc 0.9747277462121212, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.9284620098039216 | Mean Acc : 0.9615346513739308 | Median Acc 0.9601878156565656 | Max Acc 0.996826171875 \n",
      "[BZIP] Epoch[4] : Loss 3.6772323163353917, Acc 0.40007805580425915, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[4] : Loss 0.15698385836389428, Acc 0.9747277462121212, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Creating Model of type : TRANSFORMER, Batchsz = 64, Learning Rate = 0.0003\n",
      "{'Program Counter': 0, 'Set Occupancy': 1, 'Belady Friendly': 2} True\n",
      "This is the average accuracy :  0.6618220085895503  From predicting all zeros\n",
      "Logging Pre-Training Performance\n",
      "[BZIP] Epoch[-1] : Loss 0.7044548517141824, Acc 0.5201888261931629, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[-1] : Loss 0.765300269718423, Acc 0.3654450757575758, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.701125 | Mean Acc : 0.9401192665603791 | Median Acc 0.956060606060606 | Max Acc 0.997375 \n",
      "[BZIP] Epoch[0] : Loss 2.235841367911894, Acc 0.34429878300733974, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[0] : Loss 0.11972670580232234, Acc 0.9745871212121212, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.8547878787878788 | Mean Acc : 0.9535062640194418 | Median Acc 0.956060606060606 | Max Acc 0.997375 \n",
      "[BZIP] Epoch[1] : Loss 2.1820620062771297, Acc 0.3990203398935673, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[1] : Loss 0.11855516842368877, Acc 0.9745871212121212, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.14575 | Mean Acc : 0.9018921411133622 | Median Acc 0.956060606060606 | Max Acc 0.997375 \n",
      "[BZIP] Epoch[2] : Loss 1.107961668725796, Acc 0.3868436931869804, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[2] : Loss 0.2487490422402819, Acc 0.9745871212121212, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.6933333333333334 | Mean Acc : 0.9431487409627882 | Median Acc 0.9603636363636363 | Max Acc 0.997375 \n",
      "[BZIP] Epoch[3] : Loss 2.4802479144303784, Acc 0.38049339378578284, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[3] : Loss 0.11997849143208993, Acc 0.9745871212121212, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.30675 | Mean Acc : 0.91296227192458 | Median Acc 0.956060606060606 | Max Acc 0.997375 \n",
      "[BZIP] Epoch[4] : Loss 3.626606728934351, Acc 0.39971411410984053, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[4] : Loss 0.15622292402434995, Acc 0.9745871212121212, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Creating Model of type : TRANSFORMER_1, Batchsz = 64, Learning Rate = 0.0003\n",
      "{'Program Counter': 0, 'Set Occupancy': 1, 'Belady Friendly': 2} True\n",
      "This is the average accuracy :  0.6618220085895503  From predicting all zeros\n",
      "Logging Pre-Training Performance\n",
      "[BZIP] Epoch[-1] : Loss 0.6567701591492476, Acc 0.6253999176461882, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[-1] : Loss 0.8699664118502176, Acc 0.25538712318497475, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.61767578125 | Mean Acc : 0.9329978411742044 | Median Acc 0.956478851010101 | Max Acc 0.996826171875 \n",
      "[BZIP] Epoch[0] : Loss 2.2045109750793968, Acc 0.34376100241104557, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[0] : Loss 0.11993878353634059, Acc 0.9747277462121212, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.852114898989899 | Mean Acc : 0.9534027639022095 | Median Acc 0.956478851010101 | Max Acc 0.996826171875 \n",
      "[BZIP] Epoch[1] : Loss 2.2025455341633173, Acc 0.40007805580425915, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[1] : Loss 0.1178568174796193, Acc 0.9747277462121212, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.9284620098039216 | Mean Acc : 0.9615241376575744 | Median Acc 0.9601878156565656 | Max Acc 0.996826171875 \n",
      "[BZIP] Epoch[2] : Loss 1.867543198298673, Acc 0.40007805580425915, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[2] : Loss 0.12421064285180447, Acc 0.9747277462121212, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.9284620098039216 | Mean Acc : 0.961484170830923 | Median Acc 0.9601878156565656 | Max Acc 0.996826171875 \n",
      "[BZIP] Epoch[3] : Loss 2.3797383575688906, Acc 0.40007805580425915, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[3] : Loss 0.11873038083572421, Acc 0.9747277462121212, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.9284620098039216 | Mean Acc : 0.9593593331318241 | Median Acc 0.956478851010101 | Max Acc 0.996826171875 \n",
      "[BZIP] Epoch[4] : Loss 3.257078283866784, Acc 0.40007805580425915, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[4] : Loss 0.14127548933130596, Acc 0.9747277462121212, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Creating Model of type : TRANSFORMER_2, Batchsz = 64, Learning Rate = 0.0003\n",
      "{'Program Counter': 0, 'Set Occupancy': 1, 'Belady Friendly': 2} True\n",
      "This is the average accuracy :  0.6618220085895503  From predicting all zeros\n",
      "Logging Pre-Training Performance\n",
      "[BZIP] Epoch[-1] : Loss 0.6653988576344921, Acc 0.6336623744416605, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[-1] : Loss 1.0362951351668346, Acc 0.06002283577967172, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.31494140625 | Mean Acc : 0.9118734837607843 | Median Acc 0.956478851010101 | Max Acc 0.996826171875 \n",
      "[BZIP] Epoch[0] : Loss 2.6534100780890455, Acc 0.34376100241104557, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[0] : Loss 0.11948780926071446, Acc 0.9747277462121212, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.03630050505050505 | Mean Acc : 0.8608795629067669 | Median Acc 0.9540325126262625 | Max Acc 0.996826171875 \n",
      "[BZIP] Epoch[1] : Loss 2.3373939236220833, Acc 0.34376100241104557, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[1] : Loss 0.11863922441173627, Acc 0.9747277462121212, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.026204427083333332 | Mean Acc : 0.8304343243545359 | Median Acc 0.956478851010101 | Max Acc 0.996826171875 \n",
      "[BZIP] Epoch[2] : Loss 0.6587432265409001, Acc 0.6562389975889543, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[2] : Loss 1.2996993364596907, Acc 0.025272253787878788, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.04332386363636364 | Mean Acc : 0.7861807974229299 | Median Acc 0.9523996862002376 | Max Acc 0.996826171875 \n",
      "[BZIP] Epoch[3] : Loss 2.699047837673535, Acc 0.34376100241104557, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[3] : Loss 0.12000518449702102, Acc 0.9747277462121212, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n",
      "Min Acc 0.017985026041666668 | Mean Acc : 0.839976343994037 | Median Acc 0.9540325126262625 | Max Acc 0.996826171875 \n",
      "[BZIP] Epoch[4] : Loss 4.865089099805821, Acc 0.34376100241104557, Major [0] Acc 0.656989378278163, Marjor [1] Acc 0.3430106217218373\n",
      "[GRAPH] Epoch[4] : Loss 0.18757516802758223, Acc 0.9747277462121212, Major [0] Acc 0.026021041058635064, Marjor [1] Acc 0.973978958941365\n"
     ]
    }
   ],
   "source": [
    "batch_szs = [32, 64]\n",
    "lrs = [1e-4, 3e-4]\n",
    "model_types = ['TRANSFORMER', \"TRANSFORMER_1\", \"TRANSFORMER_2\"]\n",
    "\n",
    "for BATCH_SZ in batch_szs:\n",
    "    for LR in lrs:\n",
    "        for MODEL_TYPE in model_types:\n",
    "            MODEL_DESC = \"{}-{}_BSZ.{}_LR.{}\".format(TR_DESC, MODEL_TYPE, BATCH_SZ, LR)\n",
    "            model_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_columns = ['Program Counter', 'Physical Address', 'Set', 'Cache Friendly']\n",
    "dataset = csv_to_data(DATA_PATH, chosen_columns)\n",
    "pcs = dataset[:, 0]\n",
    "dict_ = defaultdict(int)\n",
    "for id_ in pcs:\n",
    "    dict_[id_] += 1\n",
    "values = np.array(list(dict_.values()))\n",
    "bc = np.bincount(values)\n",
    "print(len(values), dataset.shape, values.mean(), values.max(), values.min(), np.median(values))\n",
    "print(bc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
