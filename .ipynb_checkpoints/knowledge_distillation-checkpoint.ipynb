{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import random\n",
    "from models import *\n",
    "from torch.optim import Adam\n",
    "from dataformatter import *\n",
    "import torch.optim as optim\n",
    "from vanilla_kd import VanillaKD\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "\t# Esp important for ensuring deterministic behavior with CNNs\n",
    "\ttorch.backends.cudnn.deterministic = True\n",
    "\tnp.random.seed(seed)\n",
    "\trandom.seed(seed)\n",
    "\ttorch.manual_seed(seed)\n",
    "\tcuda_available = torch.cuda.is_available()\n",
    "\tif cuda_available:\n",
    "\t\ttorch.cuda.manual_seed_all(seed)\n",
    "\treturn cuda_available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 5\n",
    "DATA_PATH = '../hawkeye_trace_belady_graph.csv' # This is the CSV FILE WE ARE TRYING TO ANALYZE\n",
    "TR_DESC = 'GRAPH'\n",
    "EVAL_DATA_PATH = '../hawkeye_trace_belady_xalancbmk.csv' # This is the CSV FILE WE ARE TRYING TO ANALYZE\n",
    "EVAL_DESC = 'XALANBMK'\n",
    "\n",
    "SAVE_FLDR = 'results'\n",
    "N_EPOCHS = 5\n",
    "MAX_GRAD_NORM = 0.1\n",
    "SET_WISE = True\n",
    "RANDOM_SEED = 140982301"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set location of the teacher model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model_file=\"GRAPH-TRANSFORMER_BSZ.64_LR.0.0001_saved_model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRANSFORMER 64 0.0001\n"
     ]
    }
   ],
   "source": [
    "MODEL_TYPE=teacher_model_file.split(\"_\")[0].split('-')[1]\n",
    "MODEL_DESC='{} MODEL'.format(MODEL_TYPE)\n",
    "BATCH_SZ=int(teacher_model_file.split(\"_\")[1].split('.')[1])\n",
    "LR=float(teacher_model_file.split(\"_\")[2][3:])\n",
    "print(MODEL_TYPE,BATCH_SZ,LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(RANDOM_SEED)\n",
    "teacher_model = get_model(MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_columns = teacher_model.get_data_columns()\n",
    "train_dataset = csv_to_data(DATA_PATH, chosen_columns)\n",
    "eval_dataset = csv_to_data(EVAL_DATA_PATH, chosen_columns)\n",
    "\n",
    "average_pred = np.mean(train_dataset[:, -1])\n",
    "if torch.cuda.is_available():\n",
    "    teacher_model.cuda()\n",
    "\n",
    "# teacher_model.load_state_dict(torch.load('../teacher_FC.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SET_WISE:\n",
    "    train_setwise_dataset = group_by_set(train_dataset)\n",
    "    eval_setwise_dataset = group_by_set(eval_dataset)\n",
    "    all_tr_keys = list(train_setwise_dataset.keys())\n",
    "    val_keys = np.random.choice(all_tr_keys, size=int(0.1 * len(all_tr_keys)))\n",
    "    tr_keys = set(all_tr_keys) - set(val_keys)\n",
    "\n",
    "    vals = [len(x) for x in list(train_setwise_dataset.values())]\n",
    "    max_key = all_tr_keys[np.argmax(vals)]\n",
    "    teacher_model.use_cuda=torch.cuda.is_available()\n",
    "    teacher_model.prep_for_data(train_setwise_dataset[max_key], temp_order=True)\n",
    "    \n",
    "    for set_id, this_dataset in train_setwise_dataset.items():\n",
    "        teacher_model.remap_embedders(this_dataset, set_id)\n",
    "\n",
    "#     tr_val_setwise_dataset = {k: train_setwise_dataset[k] for k in val_keys}\n",
    "#     train_setwise_dataset = {k: train_setwise_dataset[k] for k in tr_keys}\n",
    "else:\n",
    "    teacher_model.prep_for_data(train_dataset, temp_order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_model.load_state_dict(torch.load('./pytorch_c++/'+teacher_model_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model_initialization='SFC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TC True\n",
      "MLP(\n",
      "  (loss_fn): CrossEntropyLoss()\n",
      "  (model): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=2, bias=True)\n",
      "  )\n",
      "  (pc_embedding): Embedding(500, 64)\n",
      "  (set_occ_embedding): Embedding(500, 64)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(SAVE_FLDR):\n",
    "    os.makedirs(SAVE_FLDR)\n",
    "\n",
    "student_model = get_model(student_model_initialization)\n",
    "\n",
    "# student_model=copy.deepcopy(teacher_model)\n",
    "# chosen_columns = student_model.get_data_columns()\n",
    "\n",
    "\n",
    "vals = [len(x) for x in list(train_setwise_dataset.values())]\n",
    "max_key = all_tr_keys[np.argmax(vals)]\n",
    "# student_model.use_cuda=True\n",
    "print(\"TC\",torch.cuda.is_available())\n",
    "student_model.use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# student_model.prep_for_data(train_setwise_dataset[max_key], temp_order=True)\n",
    "\n",
    "student_model.pc_emb_map=copy.deepcopy(teacher_model.pc_emb_map) # clone\n",
    "student_model.set_occ_emb_map= copy.deepcopy(teacher_model.set_occ_emb_map) # clone\n",
    "student_model.setid_to_map_map=copy.deepcopy(teacher_model.setid_to_map_map) #clone\n",
    "\n",
    "student_model.pc_embedding=nn.Embedding.from_pretrained(teacher_model.pc_embedding.weight.clone().detach(),freeze=True) \n",
    "student_model.set_occ_embedding=nn.Embedding.from_pretrained(teacher_model.set_occ_embedding.weight.clone().detach(),freeze=True)# clone and detach\n",
    "\n",
    "# if(student_model_initialization==\"ST\"):\n",
    "    \n",
    "for set_id, this_dataset in train_setwise_dataset.items():\n",
    "    student_model.remap_embedders(this_dataset, set_id)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    student_model.cuda()\n",
    "\n",
    "print(student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_optimizer = Adam(student_model.parameters(), lr=1e-4)\n",
    "teacher_optimizer = Adam(teacher_model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "distiller = VanillaKD(teacher_model, student_model,teacher_optimizer, student_optimizer,\n",
    "                      train_setwise_dataset,BATCH_SZ,False,student_type=student_model_initialization,\n",
    "                      distil_weight=0.5,temp=20.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Student...\n",
      "Epoch: 0 | Student Average Accuracy:0.9024984679031053 Student Median Accuracy:1.0 |Distillation Loss: 0.45778968930244446\n",
      "Epoch: 0 | Teacher Average Accuracy:0.9430225392364279 Teacher Median Accuracy:1.0 \n",
      "Epoch: 1 | Student Average Accuracy:0.9430225392364279 Student Median Accuracy:1.0 |Distillation Loss: 0.033493876457214355\n",
      "Epoch: 1 | Teacher Average Accuracy:0.9430225392364279 Teacher Median Accuracy:1.0 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5b8ebcc007e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdistiller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_student\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/project/15740_Project/base_class.py\u001b[0m in \u001b[0;36mtrain_student\u001b[0;34m(self, epochs, plot_losses, save_model, save_model_pth)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0msave_model_pth\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPath\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0myou\u001b[0m \u001b[0mwant\u001b[0m \u001b[0mto\u001b[0m \u001b[0msave\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstudent\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \t\t\"\"\"\n\u001b[0;32m--> 155\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_student\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_kd_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_student\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_teacher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project/15740_Project/base_class.py\u001b[0m in \u001b[0;36m_train_student\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m    107\u001b[0m                                 \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                                         \u001b[0mloss_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mteacher_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_window_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteacher_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                                         \u001b[0macc_t\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macc_t\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project/15740_Project/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpos_embed\u001b[0m  \u001b[0;31m# Add the positional embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                 \u001b[0mm_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;31m#               print(\"Encoder output M_out\",m_out.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m                 \u001b[0mm_out1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m         for hook in itertools.chain(\n\u001b[0m\u001b[1;32m    717\u001b[0m                 \u001b[0m_global_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                 self._forward_pre_hooks.values()):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "distiller.train_student(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE_FLDR=\"results\"\n",
    "# torch.save(distiller.student_model.state_dict(), '{}/{}_saved_model.pth'.format(SAVE_FLDR,'STUDENT_'+student_model_initialization))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
